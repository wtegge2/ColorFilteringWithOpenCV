{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Color Filtering\n",
    "\n",
    "Check that you have the necessary packages/requirements in order to run this code. Make sure you run the cells in order. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORTS\n",
    "import cv2\n",
    "import numpy as np\n",
    "from sklearn.cluster import DBSCAN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## filter_and_obtain_coordinates function\n",
    "\n",
    "This function takes in an image, the lower color bound values, and the upper color bound values. The lower and upper bound values are simply the HSV values of the color (or range of colors) you want to identify (not filter out). To learn more about RGB and HSV, go to this site: [HSV](https://web.cs.uni-paderborn.de/cgvb/colormaster/web/color-systems/hsv.html). You can also use that site to figure out what the HSV values should be for your color(s). It is useful to input a lower and upper bound so that you can keep colors of the same type/shade with more accuracy. \n",
    "\n",
    "cvtColor() is called in order to convert our image from the RGB colorspace to the HSV colorspace because it is easier to identify/filter colors this way. inRange() is used to find all the pixels of the inputted image that are within the specified lower and upper bounds in order to build a mask which will be used for the filtering. It sets every pixel to be black if it is not in our specified range. Afterwards, the function uses a bitwise-and to apply the mask to the image.  The final step is to grab all of the coordinates of the pixels that were not blacked out by the mask and store them all in a list using the argwhere() function.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to filter out everything except the specified color and return the coordinates\n",
    "# makes everything black that isnt our specified color (zeroes it out)\n",
    "def filter_and_obtain_coordinates(image, lower_color, upper_color):\n",
    "    hsv_image = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)                      # converts image from the RGB space to the HSV image space\n",
    "\n",
    "    mask = cv2.inRange(hsv_image, lower_color, upper_color)                 # creates the mask \n",
    "    \n",
    "    result = cv2.bitwise_and(image, image, mask=mask)                       # applies the mask to the image\n",
    "\n",
    "    coordinates = np.argwhere(mask > 0)                                     # finds the colored coordinates (not blacked out)\n",
    "\n",
    "    return result, coordinates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## get_cluster_centers function \n",
    "\n",
    "This function takes in a list of coordinates, a min_samples value, and an eps value. In our case, the coordinates argument is a list of coordinates of every pixel that was not blacked out in our filtering function. The eps argument defines the max distance that two points can be apart such that they are still considered to be part of eachothers neighborhoods. The min_samples argument is a number that specifies the minimum number of points in the neighborhood of any given point in order for that point to be considered a \"center\". If this value is set high then DBSCAN will find a dense cluster. Learn more about how DBSCAN works here: [DBSCAN](https://scikit-learn.org/stable/modules/generated/sklearn.cluster.DBSCAN.html)\n",
    "\n",
    "The point of this function is to group pixels together into clusters and find the center of the clusters. This is helpful because it can identify different objects of the same color in the image since the objects will give two different clusters of pixels and two different center coordinates. In my project, I want to identify all skittles of the same color which means I need one cluster of pixels and one center coordinate for each skittle on the screen. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to find and return the center coordinates of clusters\n",
    "# DBSCAN (Density-Based Spatial Clustering of Applications with Noise) algorithm\n",
    "# identifies clusters and calculates their centers\n",
    "def get_cluster_centers(coordinates, eps=10, min_samples=10):\n",
    "    db = DBSCAN(eps=eps, min_samples=min_samples).fit(coordinates)\n",
    "    \n",
    "    labels = db.labels_                                                     # cluster labels for each pixel (sets noise to -1)\n",
    "\n",
    "    unique_labels = set(labels) - {-1}                                      # Find the unique labels (besides the noise points (-1))\n",
    "\n",
    "    cluster_centers = []                                                    # list to store all the center coordinates\n",
    "\n",
    "    for label in unique_labels:                                             # loop through each unique label\n",
    "        indices = np.where(labels == label)[0]                              # get the indices of where the unique labels are\n",
    "\n",
    "        cluster_points = coordinates[indices]                               # get the coordinates of pixels with unique labels\n",
    "\n",
    "        center = np.mean(cluster_points, axis=0)                            # find the mean of all the pixel values to find the center \n",
    "\n",
    "        cluster_centers.append(center)                                      # save all the center coordinates of the clusters \n",
    "\n",
    "    return cluster_centers                                                  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is my algorithm to identify objects of a specified color in an image:\n",
    "1. Set the lower and upper HSV bounds\n",
    "2. Open the camera \n",
    "3. Filter the image \n",
    "4. Get the coordinates of the pixels of our specified color\n",
    "5. Identify pixel clusters\n",
    "6. Find the center coordinates of each cluster and save them\n",
    "7. Mark the centers of each cluster in the image\n",
    "8. Save the cluster centers, original image, and filtered image\n",
    "9. Close the camera"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# START OF CODE\n",
    "\n",
    "# Choose which color you want to detect\n",
    "# HSV -> Hue, Saturation, value\n",
    "\n",
    "# BLUE\n",
    "# lower_blue = np.array([90, 50, 50])                               # Lower bound for blue in HSV\n",
    "# upper_blue = np.array([130, 255, 255])                            # Upper bound for blue in HSV\n",
    "\n",
    "# GREEN\n",
    "# lower_blue = np.array([35, 50, 50])                               # Lower bound for green in HSV\n",
    "# upper_blue = np.array([85, 255, 255])                             # Upper bound for green in HSV\n",
    "\n",
    "# RED\n",
    "lower_blue = np.array([0, 50, 50])                                  # Lower bound for red in HSV\n",
    "upper_blue = np.array([10, 255, 255])                               # Upper bound for red in HSV\n",
    "\n",
    "\n",
    "cam = cv2.VideoCapture(0)                                           # Opens the camera\n",
    "\n",
    "if not cam.isOpened():                                              # exits if the camera can't be or isn't opened\n",
    "    print(\"Error: Could not open the camera.\")\n",
    "    exit()\n",
    "\n",
    "screenshot = None\n",
    "screenshot_coordinates = None\n",
    "\n",
    "                                                                    # Get the frame dimensions (width and height)\n",
    "width = int(cam.get(3))                                             # 3 -> CV_CAP_PROP_FRAME_WIDTH\n",
    "height = int(cam.get(4))                                            # 4 -> CV_CAP_PROP_FRAME_HEIGHT\n",
    "\n",
    "\n",
    "with open(\"screen_dimensions.txt\", \"w\") as dimensions_file:         # Saves the dimensions of the camera screen to screen_dimensions.txt\n",
    "    dimensions_file.write(f\"Width: {width} pixels\\n\")         \n",
    "    dimensions_file.write(f\"Height: {height} pixels\\n\")\n",
    "\n",
    "while True:                                                         # loop to check for errors              \n",
    "    ret, frame = cam.read()\n",
    "    if not ret:                                                     # errors out if a frame cannot be read          \n",
    "        print(\"Error: Could not read a frame.\")\n",
    "        break\n",
    "\n",
    "\n",
    "    filtered_frame, color_coordinates = filter_and_obtain_coordinates(frame, lower_blue, upper_blue)        # calls our filter function\n",
    "\n",
    "    cv2.imshow(\"Filtered Image\", filtered_frame)                    # shows the filtered frame on the screen\n",
    "\n",
    "    key_press = cv2.waitKey(1)                                      # waits for a key to be pressed\n",
    "\n",
    "\n",
    "    if key_press == ord('q'):                                       # if 'q' is pressed, takes a screenshot \n",
    "        screenshot = frame.copy()\n",
    "        screenshot_coordinates = color_coordinates\n",
    "\n",
    "\n",
    "        centers = get_cluster_centers(screenshot_coordinates)       # Get the center coordinates of the clusters\n",
    "\n",
    "\n",
    "        for center in centers:                                      # loop through a draw green circles at the cluster centers\n",
    "            center = (int(center[1]), int(center[0]))               # Swap X and Y values (for OpenCV)\n",
    "            cv2.circle(screenshot, center, 5, (0, 255, 0), -1)\n",
    "\n",
    "\n",
    "\n",
    "        with open(\"coordinates.txt\", \"w\") as coord_file:            # saves all the coordinates to coordinates.txt\n",
    "            for center in centers:\n",
    "                coord_file.write(f\"({int(center[1])}, {int(center[0])})\\n\")\n",
    "\n",
    "    \n",
    "        cv2.imwrite(\"screenshot.png\", screenshot)                   # save the screenshot of the normal image (before filtering)\n",
    "\n",
    "\n",
    "        cv2.imwrite(\"blacked_out.png\", filtered_frame)              # save a screenshot of the filtered image\n",
    "\n",
    "\n",
    "        print(\"Screenshot taken and saved as 'screenshot.png'.\")    # print confirmation \n",
    "        print(\"Coordinates saved to 'coordinates.txt'.\")\n",
    "        print(\"Blacked-out image saved as 'blacked_out.png'.\")\n",
    "        break\n",
    "\n",
    "\n",
    "cam.release()                                                       # release the camera \n",
    "cv2.destroyAllWindows()                                             # close all OpenCV windows"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
