{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Color Filtering\n",
    "\n",
    "Check that you have the necessary packages/requirements in order to run this code. Make sure you run the cells in order. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORTS\n",
    "import cv2\n",
    "import numpy as np\n",
    "from sklearn.cluster import DBSCAN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## filter_and_obtain_coordinates function\n",
    "\n",
    "This function takes in an image, the lower color bound values, and the upper color bound values. The lower and upper bound values are simply the HSV values of the color (or range of colors) you want to identify (not filter out). To learn more about RGB and HSV, go to this site: [HSV](https://web.cs.uni-paderborn.de/cgvb/colormaster/web/color-systems/hsv.html). You can also use that site to figure out what the HSV values should be for your color(s). It is useful to input a lower and upper bound so that you can keep colors of the same type/shade with more accuracy. \n",
    "\n",
    "cvtColor() is called in order to convert our image from the RGB colorspace to the HSV colorspace because it is easier to identify/filter colors this way. inRange() is used to find all the pixels of the inputted image that are within the specified lower and upper bounds in order to build a mask which will be used for the filtering. It sets every pixel to be black if it is not in our specified range. Afterwards, the function uses a bitwise-and to apply the mask to the image.  The final step is to grab all of the coordinates of the pixels that were not blacked out by the mask and store them all in a list using the argwhere() function.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to filter out everything except the specified color and return the coordinates\n",
    "# makes everything black that isnt our specified color (zeroes it out)\n",
    "def filter_and_obtain_coordinates(image, lower_color, upper_color):\n",
    "    hsv_image = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "    mask = cv2.inRange(hsv_image, lower_color, upper_color)\n",
    "    \n",
    "    result = cv2.bitwise_and(image, image, mask=mask)\n",
    "\n",
    "    coordinates = np.argwhere(mask > 0)                                     # Finds the colored coordinates (not blacked out)\n",
    "\n",
    "    return result, coordinates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## get_cluster_centers function \n",
    "\n",
    "Thid function takes in a list of coordinates, a min_samples value, and an eps value. In our case, the coordinates argument is a list of coordinates of every pixel that was not blacked out in our filtering function. The eps argument defines the max distance that two points can be apart such that they are still considered to be part of eachothers neighborhoods. The min_samples argument is a number that specifies the minimum number of points in the neighborhood of any given point in order for that point to be considered a \"center\". If this value is set high then DBSCAN will find a dense cluster. Learn more about how DBSCAN works here: [DBSCAN](https://scikit-learn.org/stable/modules/generated/sklearn.cluster.DBSCAN.html)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to find and return the center coordinates of clusters\n",
    "# DBSCAN (Density-Based Spatial Clustering of Applications with Noise) algorithm\n",
    "# identifies clusters and calculates their centers\n",
    "def get_cluster_centers(coordinates, eps=10, min_samples=10):\n",
    "    db = DBSCAN(eps=eps, min_samples=min_samples).fit(coordinates)\n",
    "    \n",
    "    labels = db.labels_\n",
    "\n",
    "    unique_labels = set(labels) - {-1}                                      # Find the unique labels (besides the noise points (-1))\n",
    "\n",
    "    cluster_centers = []                                                    # List to store all the center coordinates\n",
    "\n",
    "    for label in unique_labels:\n",
    "        cluster_indices = np.where(labels == label)[0]\n",
    "        cluster_points = coordinates[cluster_indices]\n",
    "\n",
    "        center = np.mean(cluster_points, axis=0)\n",
    "        cluster_centers.append(center)\n",
    "\n",
    "    return cluster_centers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# START OF CODE\n",
    "\n",
    "# Choose which color you want to detect\n",
    "# HSV -> Hue, Saturation, value\n",
    "\n",
    "# BLUE\n",
    "# lower_blue = np.array([90, 50, 50])                               # Lower bound for blue in HSV\n",
    "# upper_blue = np.array([130, 255, 255])                            # Upper bound for blue in HSV\n",
    "\n",
    "# GREEN\n",
    "# lower_blue = np.array([35, 50, 50])                               # Lower bound for green in HSV\n",
    "# upper_blue = np.array([85, 255, 255])                             # Upper bound for green in HSV\n",
    "\n",
    "# RED\n",
    "lower_blue = np.array([0, 50, 50])                                  # Lower bound for red in HSV\n",
    "upper_blue = np.array([10, 255, 255])                               # Upper bound for red in HSV\n",
    "\n",
    "\n",
    "cap = cv2.VideoCapture(0)                                           # Opens the camera\n",
    "\n",
    "if not cap.isOpened():                                              # exits if the camera can't be or isn't opened\n",
    "    print(\"Error: Could not open the camera.\")\n",
    "    exit()\n",
    "\n",
    "screenshot = None\n",
    "screenshot_coordinates = None\n",
    "\n",
    "                                                                    # Get the frame dimensions (width and height)\n",
    "frame_width = int(cap.get(3))                                       # 3 corresponds to CV_CAP_PROP_FRAME_WIDTH\n",
    "frame_height = int(cap.get(4))                                      # 4 corresponds to CV_CAP_PROP_FRAME_HEIGHT\n",
    "\n",
    "\n",
    "with open(\"screen_dimensions.txt\", \"w\") as dimensions_file:         # Saves the dimensions of the camera screen to screen_dimensions.txt\n",
    "    dimensions_file.write(f\"Width: {frame_width} pixels\\n\")         \n",
    "    dimensions_file.write(f\"Height: {frame_height} pixels\\n\")\n",
    "\n",
    "while True:                                                         \n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        print(\"Error: Could not read a frame.\")\n",
    "        break\n",
    "\n",
    "\n",
    "    filtered_frame, color_coordinates = filter_and_obtain_coordinates(frame, lower_blue, upper_blue)        # calls our filter function\n",
    "\n",
    "    cv2.imshow(\"Filtered Image\", filtered_frame)                    # shows the filtered frame on the screen\n",
    "\n",
    "    key = cv2.waitKey(1)                                            # waits for a key to be pressed\n",
    "\n",
    "\n",
    "    if key == ord('q'):                                             # if 'q' is pressed, takes a screenshot \n",
    "        screenshot = frame.copy()\n",
    "        screenshot_coordinates = color_coordinates\n",
    "\n",
    "\n",
    "        cluster_centers = get_cluster_centers(screenshot_coordinates)   # Get the center coordinates of the clusters\n",
    "\n",
    "\n",
    "        for center in cluster_centers:                              # loop through a draw green circles at the cluster centers\n",
    "            center = (int(center[1]), int(center[0]))               # Swap X and Y values (for OpenCV)\n",
    "            cv2.circle(screenshot, center, 5, (0, 255, 0), -1)\n",
    "\n",
    "\n",
    "\n",
    "        with open(\"coordinates.txt\", \"w\") as coord_file:            # Saves all the coordinates to coordinates.txt\n",
    "            for center in cluster_centers:\n",
    "                coord_file.write(f\"({int(center[1])}, {int(center[0])})\\n\")\n",
    "\n",
    "    \n",
    "        cv2.imwrite(\"screenshot.png\", screenshot)                   # Save the screenshot\n",
    "\n",
    "\n",
    "        cv2.imwrite(\"blacked_out.png\", filtered_frame)              # Save a screenshot of the filtered image\n",
    "\n",
    "\n",
    "        print(\"Screenshot taken and saved as 'screenshot.png'.\")    # print confirmation\n",
    "        print(\"Coordinates saved to 'coordinates.txt'.\")\n",
    "        print(\"Blacked-out image saved as 'blacked_out.png'.\")\n",
    "        break\n",
    "\n",
    "\n",
    "cap.release()                                                       # release the camera \n",
    "cv2.destroyAllWindows()                                             # close all OpenCV windows"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
